{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgkqmpgqDKX1"
      },
      "source": [
        "# Model Training\n",
        "\n",
        "This notebook is designed for training the models used in the Legal NLP + Explainability Toolkit project. It includes the necessary steps to fine-tune the BERT model for clause extraction and the T5 or GPT-4 model for summarization tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "tfmSnsXxDKX2"
      },
      "source": [
        "#### Import necessary libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZYosfWDDKX2",
        "outputId": "69b4b525-dbb7-4811-8b1b-c7a2c1b15711"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer, AutoModel, AutoModelForSequenceClassification,\n",
        "    BertTokenizer, BertForSequenceClassification,\n",
        "    Trainer, TrainingArguments\n",
        ")\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4z8e41q9fR2f",
        "outputId": "6d1e84e9-a1c7-417b-aa05-f6387f425e42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/notebooks\n"
          ]
        }
      ],
      "source": [
        "%cd /content/notebooks/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJRMz42PDKX2"
      },
      "source": [
        "#### Load Preprocessed Data and Metadata\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRK3veDLDKX2",
        "outputId": "1bace4e9-205c-46ee-d436-bfe97a492090"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Dataset Overview ===\n",
            "Total clause types: 41\n",
            "Clean clause names available: True\n",
            "Train size: 6092\n",
            "Val size: 871\n",
            "Test size: 1741\n",
            "Available datasets: ['multi_label', 'binary_affiliate_license_licensee', 'binary_affiliate_license_licensor', 'binary_agreement_date', 'binary_anti_assignment', 'binary_audit_rights', 'binary_cap_on_liability', 'binary_change_of_control', 'binary_competitive_restriction_except', 'binary_covenant_not_to_sue', 'binary_document_name', 'binary_effective_date', 'binary_exclusivity', 'binary_expiration_date', 'binary_governing_law', 'binary_insurance', 'binary_ip_ownership_assignment', 'binary_irrevocable_or_perpetual_licen', 'binary_joint_ip_ownership', 'binary_license_grant', 'binary_liquidated_damages', 'binary_minimum_commitment', 'binary_most_favored_nation', 'binary_no_solicit_of_customers', 'binary_no_solicit_of_employees', 'binary_non_compete', 'binary_non_disparagement', 'binary_non_transferable_license', 'binary_notice_period_to_terminate_ren', 'binary_parties', 'binary_post_termination_services', 'binary_price_restrictions', 'binary_renewal_term', 'binary_revenueprofit_sharing', 'binary_rofrroforofn', 'binary_source_code_escrow', 'binary_termination_for_convenience', 'binary_third_party_beneficiary', 'binary_uncapped_liability', 'binary_unlimitedall_you_can_eat_licen', 'binary_volume_restriction', 'binary_warranty_duration', 'question_answering']\n",
            "\n",
            "Sample training data with clean clause names:\n",
            "Sample labels: ['Rofr/Rofo/Rofn', 'Post-Termination Services', 'Audit Rights']\n",
            "\n",
            "Dataset loaded with clean clause names!\n"
          ]
        }
      ],
      "source": [
        "def load_processed_data():\n",
        "    \"\"\"Load the preprocessed datasets and metadata\"\"\"\n",
        "\n",
        "    # Load metadata\n",
        "    with open('../data/processed/metadata.json', 'r') as f:\n",
        "        metadata = json.load(f)\n",
        "\n",
        "    print(\"=== Dataset Overview ===\")\n",
        "    print(f\"Total clause types: {len(metadata['clause_types'])}\")\n",
        "    print(f\"Clean clause names available: {'clean_clause_names' in metadata}\")\n",
        "    print(f\"Train size: {metadata['train_size']}\")\n",
        "    print(f\"Val size: {metadata['val_size']}\")\n",
        "    print(f\"Test size: {metadata['test_size']}\")\n",
        "    print(f\"Available datasets: {metadata['dataset_types']}\")\n",
        "\n",
        "    # Load multi-label datasets (start with these)\n",
        "    train_ml = pd.read_csv('../data/processed/train_multi_label.csv')\n",
        "    val_ml = pd.read_csv('../data/processed/val_multi_label.csv')\n",
        "    test_ml = pd.read_csv('../data/processed/test_multi_label.csv')\n",
        "\n",
        "    # Convert string representation of lists back to actual lists\n",
        "    import ast\n",
        "    for df in [train_ml, val_ml, test_ml]:\n",
        "        df['labels'] = df['labels'].apply(lambda x: ast.literal_eval(x) if pd.notna(x) else [])\n",
        "\n",
        "    # Show sample with clean names\n",
        "    print(f\"\\nSample training data with clean clause names:\")\n",
        "    sample_labels = train_ml['labels'].iloc[0] if len(train_ml) > 0 else []\n",
        "    print(f\"Sample labels: {sample_labels[:5]}{'...' if len(sample_labels) > 5 else ''}\")\n",
        "\n",
        "    return {\n",
        "        'metadata': metadata,\n",
        "        'train': train_ml,\n",
        "        'val': val_ml,\n",
        "        'test': test_ml\n",
        "    }\n",
        "\n",
        "data = load_processed_data()\n",
        "print(f\"\\nDataset loaded with clean clause names!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kj-oKtVLDKX2"
      },
      "source": [
        "#### Multi-Label Dataset Class\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWe0TM7BDKX2",
        "outputId": "326dec64-f2e0-40a7-c34c-3ee4fa57d057"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using clean clause names:\n",
            "  'Affiliate License-Licensee' (was: Highlight the parts (if any) of this contract rela...)\n",
            "  'Affiliate License-Licensor' (was: Highlight the parts (if any) of this contract rela...)\n",
            "  'Agreement Date' (was: Highlight the parts (if any) of this contract rela...)\n",
            "  'Anti-Assignment' (was: Highlight the parts (if any) of this contract rela...)\n",
            "  'Audit Rights' (was: Highlight the parts (if any) of this contract rela...)\n",
            "  ... and 36 more\n",
            "\n",
            "Dataset sizes:\n",
            "Train: 6092\n",
            "Val: 871\n",
            "Test: 1741\n",
            "Number of clean clause types: 41\n"
          ]
        }
      ],
      "source": [
        "class LegalClauseDataset(Dataset):\n",
        "    \"\"\"Dataset class for multi-label legal clause classification with clean names\"\"\"\n",
        "\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=512, clean_clause_names=None):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "        self.clean_clause_names = clean_clause_names or []\n",
        "\n",
        "        # Create multi-label binarizer using clean clause names\n",
        "        self.mlb = MultiLabelBinarizer()\n",
        "        if clean_clause_names:\n",
        "            self.mlb.fit([clean_clause_names])  # Fit on all possible clean labels\n",
        "\n",
        "        # Convert label lists to binary matrix\n",
        "        self.label_matrix = self.mlb.transform(labels)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts.iloc[idx])\n",
        "        labels = self.label_matrix[idx]\n",
        "\n",
        "        # Tokenize\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.FloatTensor(labels)\n",
        "        }\n",
        "\n",
        "# Initialize tokenizer\n",
        "MODEL_NAME = 'bert-base-uncased'  # Start with base BERT\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "# Extract clean clause names from metadata\n",
        "metadata = data['metadata']\n",
        "if 'clean_clause_names' in metadata:\n",
        "    # Use clean clause names mapping\n",
        "    clean_clause_names_dict = metadata['clean_clause_names']\n",
        "    clean_clause_names = list(set(clean_clause_names_dict.values()))  # Get unique clean names\n",
        "\n",
        "    # Map original clause types to clean names for reference\n",
        "    original_to_clean = clean_clause_names_dict\n",
        "    print(f\"Using clean clause names:\")\n",
        "    for i, (original, clean) in enumerate(list(original_to_clean.items())[:5]):\n",
        "        print(f\"  '{clean}' (was: {original[:50]}...)\")\n",
        "    print(f\"  ... and {len(original_to_clean) - 5} more\")\n",
        "else:\n",
        "    # Fallback to original clause types\n",
        "    clean_clause_names = metadata['clause_types']\n",
        "    original_to_clean = {ct: ct for ct in clean_clause_names}\n",
        "    print(\"Using original clause types (clean names not found)\")\n",
        "\n",
        "# Create datasets with clean clause names\n",
        "train_dataset = LegalClauseDataset(\n",
        "    data['train']['text'],\n",
        "    data['train']['labels'],\n",
        "    tokenizer,\n",
        "    max_length=512,\n",
        "    clean_clause_names=clean_clause_names\n",
        ")\n",
        "\n",
        "val_dataset = LegalClauseDataset(\n",
        "    data['val']['text'],\n",
        "    data['val']['labels'],\n",
        "    tokenizer,\n",
        "    max_length=512,\n",
        "    clean_clause_names=clean_clause_names\n",
        ")\n",
        "\n",
        "test_dataset = LegalClauseDataset(\n",
        "    data['test']['text'],\n",
        "    data['test']['labels'],\n",
        "    tokenizer,\n",
        "    max_length=512,\n",
        "    clean_clause_names=clean_clause_names\n",
        ")\n",
        "\n",
        "print(f\"\\nDataset sizes:\")\n",
        "print(f\"Train: {len(train_dataset)}\")\n",
        "print(f\"Val: {len(val_dataset)}\")\n",
        "print(f\"Test: {len(test_dataset)}\")\n",
        "print(f\"Number of clean clause types: {len(clean_clause_names)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pkQe2qTDKX2"
      },
      "source": [
        "#### Multi-Label BERT Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ekf__yq4DKX3",
        "outputId": "94f13eaf-f4ab-4a9a-ffc3-433324808c29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model initialized for clean clause names:\n",
            "  Clean clause types: 41\n",
            "  Model parameters: 109,513,769\n",
            "  Example clean names: ['Parties', 'Joint Ip Ownership', 'No-Solicit Of Customers', 'Anti-Assignment', 'Cap On Liability']\n"
          ]
        }
      ],
      "source": [
        "class MultiLabelBERT(nn.Module):\n",
        "    \"\"\"BERT model for multi-label classification with clean clause names\"\"\"\n",
        "\n",
        "    def __init__(self, model_name, num_labels, dropout=0.3):\n",
        "        super(MultiLabelBERT, self).__init__()\n",
        "        self.bert = AutoModel.from_pretrained(model_name)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
        "        self.num_labels = num_labels\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.pooler_output\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            # Use BCEWithLogitsLoss for multi-label classification\n",
        "            loss_fct = nn.BCEWithLogitsLoss()\n",
        "            loss = loss_fct(logits, labels)\n",
        "\n",
        "        return {'loss': loss, 'logits': logits}\n",
        "\n",
        "# Initialize model with clean clause names count\n",
        "num_labels = len(clean_clause_names)\n",
        "model = MultiLabelBERT(MODEL_NAME, num_labels)\n",
        "model.to(device)\n",
        "\n",
        "print(f\"Model initialized for clean clause names:\")\n",
        "print(f\"  Clean clause types: {num_labels}\")\n",
        "print(f\"  Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "print(f\"  Example clean names: {clean_clause_names[:5]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Mx8buxkDKX3"
      },
      "source": [
        "#### Training Configuration with Class Imbalance Handling\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24tqfRctDKX3",
        "outputId": "feea23ce-47ef-42f9-d0a1-e7805210b190"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class imbalance handling:\n",
            "  Most frequent clause: ('Governing Law', 657)\n",
            "  Least frequent clause: ('Exclusivity', 1)\n",
            "  Weight range: 0.23 - 148.59\n",
            "\n",
            "Training configuration:\n",
            "Batch size: 8\n",
            "Learning rate: 2e-05\n",
            "Epochs: 15\n",
            "Total training steps: 11430\n",
            "Using clean clause names for training\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "def create_weighted_loss():\n",
        "    \"\"\"Create weighted loss to handle class imbalance using clean clause names\"\"\"\n",
        "    # Calculate class weights based on frequency of clean clause names\n",
        "    all_labels = []\n",
        "    for labels in data['train']['labels']:\n",
        "        all_labels.extend(labels)  # These are already clean names\n",
        "\n",
        "    from collections import Counter\n",
        "    label_counts = Counter(all_labels)\n",
        "    total_samples = len(data['train'])\n",
        "\n",
        "    # Calculate weights (inverse frequency) for clean clause names\n",
        "    weights = []\n",
        "    for clean_clause_name in clean_clause_names:\n",
        "        count = label_counts.get(clean_clause_name, 1)\n",
        "        weight = total_samples / (len(clean_clause_names) * count)\n",
        "        weights.append(weight)\n",
        "\n",
        "    print(f\"Class imbalance handling:\")\n",
        "    print(f\"  Most frequent clause: {max(label_counts.items(), key=lambda x: x[1])}\")\n",
        "    print(f\"  Least frequent clause: {min(label_counts.items(), key=lambda x: x[1])}\")\n",
        "    print(f\"  Weight range: {min(weights):.2f} - {max(weights):.2f}\")\n",
        "\n",
        "    return torch.FloatTensor(weights).to(device)\n",
        "\n",
        "# Training parameters\n",
        "BATCH_SIZE = 8  # Small batch size due to long sequences\n",
        "LEARNING_RATE = 2e-5\n",
        "EPOCHS = 15\n",
        "MAX_GRAD_NORM = 1.0\n",
        "\n",
        "# Data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# Optimizer and scheduler\n",
        "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "total_steps = len(train_loader) * EPOCHS\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=total_steps // 10,\n",
        "    num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "# Weighted loss for class imbalance using clean clause names\n",
        "class_weights = create_weighted_loss()\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=class_weights)\n",
        "\n",
        "print(f\"\\nTraining configuration:\")\n",
        "print(f\"Batch size: {BATCH_SIZE}\")\n",
        "print(f\"Learning rate: {LEARNING_RATE}\")\n",
        "print(f\"Epochs: {EPOCHS}\")\n",
        "print(f\"Total training steps: {total_steps}\")\n",
        "print(f\"Using clean clause names for training\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lGiAxtQDKX3"
      },
      "source": [
        "#### Training Loop with Metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OIhZc_wDKX3",
        "outputId": "e0deee0e-03dd-4c73-9225-7ad5471bbc19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training...\n",
            "\n",
            "=== Epoch 1/15 ===\n",
            "Batch 0/762, Loss: 0.9609\n",
            "Batch 50/762, Loss: 1.3163\n",
            "Batch 100/762, Loss: 0.6149\n",
            "Batch 150/762, Loss: 0.5611\n",
            "Batch 200/762, Loss: 0.4957\n",
            "Batch 250/762, Loss: 0.9512\n",
            "Batch 300/762, Loss: 0.8822\n",
            "Batch 350/762, Loss: 0.3639\n",
            "Batch 400/762, Loss: 0.8675\n",
            "Batch 450/762, Loss: 0.4256\n",
            "Batch 500/762, Loss: 0.2886\n",
            "Batch 550/762, Loss: 0.2089\n",
            "Batch 600/762, Loss: 0.4278\n",
            "Batch 650/762, Loss: 1.1663\n",
            "Batch 700/762, Loss: 0.6154\n",
            "Batch 750/762, Loss: 0.9112\n",
            "Training Loss: 0.6476\n",
            "Validation Metrics:\n",
            "  loss: 0.6077\n",
            "  precision_micro: 0.6667\n",
            "  recall_micro: 0.0231\n",
            "  f1_micro: 0.0446\n",
            "  precision_macro: 0.0244\n",
            "  recall_macro: 0.0152\n",
            "  f1_macro: 0.0188\n",
            "  hamming_loss: 0.0120\n",
            "\n",
            "=== Epoch 2/15 ===\n",
            "Batch 0/762, Loss: 0.7738\n",
            "Batch 50/762, Loss: 0.2335\n",
            "Batch 100/762, Loss: 0.9936\n",
            "Batch 150/762, Loss: 0.2900\n",
            "Batch 200/762, Loss: 1.5709\n",
            "Batch 250/762, Loss: 0.7891\n",
            "Batch 300/762, Loss: 0.0993\n",
            "Batch 350/762, Loss: 1.4170\n",
            "Batch 400/762, Loss: 0.1270\n",
            "Batch 450/762, Loss: 0.9262\n",
            "Batch 500/762, Loss: 0.0836\n",
            "Batch 550/762, Loss: 0.0986\n",
            "Batch 600/762, Loss: 0.1125\n",
            "Batch 650/762, Loss: 1.3441\n",
            "Batch 700/762, Loss: 0.1383\n",
            "Batch 750/762, Loss: 0.0629\n",
            "Training Loss: 0.4663\n",
            "Validation Metrics:\n",
            "  loss: 0.5142\n",
            "  precision_micro: 0.2975\n",
            "  recall_micro: 0.0831\n",
            "  f1_micro: 0.1300\n",
            "  precision_macro: 0.0965\n",
            "  recall_macro: 0.0671\n",
            "  f1_macro: 0.0652\n",
            "  hamming_loss: 0.0135\n",
            "\n",
            "=== Epoch 3/15 ===\n",
            "Batch 0/762, Loss: 0.0498\n",
            "Batch 50/762, Loss: 0.1199\n",
            "Batch 100/762, Loss: 2.4233\n",
            "Batch 150/762, Loss: 0.1602\n",
            "Batch 200/762, Loss: 0.2329\n",
            "Batch 250/762, Loss: 0.1082\n",
            "Batch 300/762, Loss: 0.4618\n",
            "Batch 350/762, Loss: 0.0799\n",
            "Batch 400/762, Loss: 0.1347\n",
            "Batch 450/762, Loss: 1.2719\n",
            "Batch 500/762, Loss: 0.1178\n",
            "Batch 550/762, Loss: 1.2754\n",
            "Batch 600/762, Loss: 1.4401\n",
            "Batch 650/762, Loss: 0.0617\n",
            "Batch 700/762, Loss: 0.1193\n",
            "Batch 750/762, Loss: 0.2140\n",
            "Training Loss: 0.3067\n",
            "Validation Metrics:\n",
            "  loss: 0.3443\n",
            "  precision_micro: 0.3113\n",
            "  recall_micro: 0.1848\n",
            "  f1_micro: 0.2319\n",
            "  precision_macro: 0.1077\n",
            "  recall_macro: 0.1389\n",
            "  f1_macro: 0.0984\n",
            "  hamming_loss: 0.0148\n",
            "\n",
            "=== Epoch 4/15 ===\n",
            "Batch 0/762, Loss: 0.0789\n",
            "Batch 50/762, Loss: 0.0926\n",
            "Batch 100/762, Loss: 0.0504\n",
            "Batch 150/762, Loss: 0.1456\n",
            "Batch 200/762, Loss: 0.0592\n",
            "Batch 250/762, Loss: 0.0661\n",
            "Batch 300/762, Loss: 0.1190\n",
            "Batch 350/762, Loss: 0.0410\n",
            "Batch 400/762, Loss: 0.1236\n",
            "Batch 450/762, Loss: 0.0691\n",
            "Batch 500/762, Loss: 0.0993\n",
            "Batch 550/762, Loss: 2.5239\n",
            "Batch 600/762, Loss: 0.0954\n",
            "Batch 650/762, Loss: 0.0506\n",
            "Batch 700/762, Loss: 0.0952\n",
            "Batch 750/762, Loss: 0.0468\n",
            "Training Loss: 0.1769\n",
            "Validation Metrics:\n",
            "  loss: 0.2895\n",
            "  precision_micro: 0.3728\n",
            "  recall_micro: 0.3487\n",
            "  f1_micro: 0.3604\n",
            "  precision_macro: 0.1929\n",
            "  recall_macro: 0.2321\n",
            "  f1_macro: 0.1805\n",
            "  hamming_loss: 0.0150\n",
            "\n",
            "=== Epoch 5/15 ===\n",
            "Batch 0/762, Loss: 0.0349\n",
            "Batch 50/762, Loss: 0.0939\n",
            "Batch 100/762, Loss: 0.0299\n",
            "Batch 150/762, Loss: 0.0397\n",
            "Batch 200/762, Loss: 0.0789\n",
            "Batch 250/762, Loss: 0.0287\n",
            "Batch 300/762, Loss: 0.0519\n",
            "Batch 350/762, Loss: 0.0942\n",
            "Batch 400/762, Loss: 0.0412\n",
            "Batch 450/762, Loss: 0.0826\n",
            "Batch 500/762, Loss: 0.3279\n",
            "Batch 550/762, Loss: 0.0487\n",
            "Batch 600/762, Loss: 0.0713\n",
            "Batch 650/762, Loss: 0.0549\n",
            "Batch 700/762, Loss: 0.0622\n",
            "Batch 750/762, Loss: 0.0585\n",
            "Training Loss: 0.1118\n",
            "Validation Metrics:\n",
            "  loss: 0.2908\n",
            "  precision_micro: 0.6324\n",
            "  recall_micro: 0.4965\n",
            "  f1_micro: 0.5563\n",
            "  precision_macro: 0.2822\n",
            "  recall_macro: 0.2894\n",
            "  f1_macro: 0.2618\n",
            "  hamming_loss: 0.0096\n",
            "\n",
            "=== Epoch 6/15 ===\n",
            "Batch 0/762, Loss: 0.0393\n",
            "Batch 50/762, Loss: 0.0596\n",
            "Batch 100/762, Loss: 0.0095\n",
            "Batch 150/762, Loss: 0.0587\n",
            "Batch 200/762, Loss: 0.0395\n",
            "Batch 250/762, Loss: 0.0443\n",
            "Batch 300/762, Loss: 0.1038\n",
            "Batch 350/762, Loss: 0.0490\n",
            "Batch 400/762, Loss: 0.0402\n",
            "Batch 450/762, Loss: 0.0234\n",
            "Batch 500/762, Loss: 0.0130\n",
            "Batch 550/762, Loss: 0.0681\n",
            "Batch 600/762, Loss: 0.2959\n",
            "Batch 650/762, Loss: 0.0235\n",
            "Batch 700/762, Loss: 0.0298\n",
            "Batch 750/762, Loss: 0.0621\n",
            "Training Loss: 0.0755\n",
            "Validation Metrics:\n",
            "  loss: 0.3081\n",
            "  precision_micro: 0.8223\n",
            "  recall_micro: 0.5450\n",
            "  f1_micro: 0.6556\n",
            "  precision_macro: 0.3788\n",
            "  recall_macro: 0.3219\n",
            "  f1_macro: 0.3395\n",
            "  hamming_loss: 0.0069\n",
            "\n",
            "=== Epoch 7/15 ===\n",
            "Batch 0/762, Loss: 0.0515\n",
            "Batch 50/762, Loss: 0.0199\n",
            "Batch 100/762, Loss: 0.0250\n",
            "Batch 150/762, Loss: 0.0136\n",
            "Batch 200/762, Loss: 0.0604\n",
            "Batch 250/762, Loss: 0.0111\n",
            "Batch 300/762, Loss: 0.0904\n",
            "Batch 350/762, Loss: 0.0341\n",
            "Batch 400/762, Loss: 0.0168\n",
            "Batch 450/762, Loss: 0.0282\n",
            "Batch 500/762, Loss: 0.0365\n",
            "Batch 550/762, Loss: 0.0329\n",
            "Batch 600/762, Loss: 0.0268\n",
            "Batch 650/762, Loss: 0.0790\n",
            "Batch 700/762, Loss: 0.0431\n",
            "Batch 750/762, Loss: 0.0435\n",
            "Training Loss: 0.0561\n",
            "Validation Metrics:\n",
            "  loss: 0.2879\n",
            "  precision_micro: 0.7078\n",
            "  recall_micro: 0.6097\n",
            "  f1_micro: 0.6551\n",
            "  precision_macro: 0.3632\n",
            "  recall_macro: 0.3506\n",
            "  f1_macro: 0.3466\n",
            "  hamming_loss: 0.0078\n",
            "\n",
            "=== Epoch 8/15 ===\n",
            "Batch 0/762, Loss: 0.0083\n",
            "Batch 50/762, Loss: 0.0089\n",
            "Batch 100/762, Loss: 0.0110\n",
            "Batch 150/762, Loss: 0.0233\n",
            "Batch 200/762, Loss: 0.0251\n",
            "Batch 250/762, Loss: 0.0257\n",
            "Batch 300/762, Loss: 0.0128\n",
            "Batch 350/762, Loss: 0.0183\n",
            "Batch 400/762, Loss: 0.0239\n",
            "Batch 450/762, Loss: 0.0130\n",
            "Batch 500/762, Loss: 0.0255\n",
            "Batch 550/762, Loss: 0.0137\n",
            "Batch 600/762, Loss: 0.0151\n",
            "Batch 650/762, Loss: 0.0126\n",
            "Batch 700/762, Loss: 0.0106\n",
            "Batch 750/762, Loss: 0.0304\n",
            "Training Loss: 0.0386\n",
            "Validation Metrics:\n",
            "  loss: 0.3441\n",
            "  precision_micro: 0.8567\n",
            "  recall_micro: 0.6074\n",
            "  f1_micro: 0.7108\n",
            "  precision_macro: 0.4141\n",
            "  recall_macro: 0.3548\n",
            "  f1_macro: 0.3782\n",
            "  hamming_loss: 0.0060\n",
            "\n",
            "=== Epoch 9/15 ===\n",
            "Batch 0/762, Loss: 0.0227\n",
            "Batch 50/762, Loss: 0.0027\n",
            "Batch 100/762, Loss: 0.0507\n",
            "Batch 150/762, Loss: 0.0227\n",
            "Batch 200/762, Loss: 0.0211\n",
            "Batch 250/762, Loss: 0.0281\n",
            "Batch 300/762, Loss: 0.0193\n",
            "Batch 350/762, Loss: 0.0079\n",
            "Batch 400/762, Loss: 0.0046\n",
            "Batch 450/762, Loss: 0.0116\n",
            "Batch 500/762, Loss: 0.0332\n",
            "Batch 550/762, Loss: 0.0026\n",
            "Batch 600/762, Loss: 0.0133\n",
            "Batch 650/762, Loss: 0.0500\n",
            "Batch 700/762, Loss: 0.0054\n",
            "Batch 750/762, Loss: 0.0436\n",
            "Training Loss: 0.0307\n",
            "Validation Metrics:\n",
            "  loss: 0.2785\n",
            "  precision_micro: 0.8440\n",
            "  recall_micro: 0.6374\n",
            "  f1_micro: 0.7263\n",
            "  precision_macro: 0.4460\n",
            "  recall_macro: 0.3692\n",
            "  f1_macro: 0.3920\n",
            "  hamming_loss: 0.0058\n",
            "\n",
            "=== Epoch 10/15 ===\n",
            "Batch 0/762, Loss: 0.0271\n",
            "Batch 50/762, Loss: 0.0199\n",
            "Batch 100/762, Loss: 0.0118\n",
            "Batch 150/762, Loss: 0.0090\n",
            "Batch 200/762, Loss: 0.0314\n",
            "Batch 250/762, Loss: 0.0088\n",
            "Batch 300/762, Loss: 0.0090\n",
            "Batch 350/762, Loss: 0.0092\n",
            "Batch 400/762, Loss: 0.0980\n",
            "Batch 450/762, Loss: 0.0087\n",
            "Batch 500/762, Loss: 0.0170\n",
            "Batch 550/762, Loss: 0.0241\n",
            "Batch 600/762, Loss: 0.0040\n",
            "Batch 650/762, Loss: 0.0283\n",
            "Batch 700/762, Loss: 0.0224\n",
            "Batch 750/762, Loss: 0.0108\n",
            "Training Loss: 0.0233\n",
            "Validation Metrics:\n",
            "  loss: 0.2699\n",
            "  precision_micro: 0.8585\n",
            "  recall_micro: 0.6443\n",
            "  f1_micro: 0.7361\n",
            "  precision_macro: 0.4240\n",
            "  recall_macro: 0.3750\n",
            "  f1_macro: 0.3940\n",
            "  hamming_loss: 0.0056\n",
            "\n",
            "=== Epoch 11/15 ===\n",
            "Batch 0/762, Loss: 0.0239\n",
            "Batch 50/762, Loss: 0.0055\n",
            "Batch 100/762, Loss: 0.0079\n",
            "Batch 150/762, Loss: 0.0121\n",
            "Batch 200/762, Loss: 0.0089\n",
            "Batch 250/762, Loss: 0.0125\n",
            "Batch 300/762, Loss: 0.0380\n",
            "Batch 350/762, Loss: 0.0031\n",
            "Batch 400/762, Loss: 0.0042\n",
            "Batch 450/762, Loss: 0.0047\n",
            "Batch 500/762, Loss: 0.0202\n",
            "Batch 550/762, Loss: 0.0041\n",
            "Batch 600/762, Loss: 0.0071\n",
            "Batch 650/762, Loss: 0.0206\n",
            "Batch 700/762, Loss: 0.0037\n",
            "Batch 750/762, Loss: 0.0248\n",
            "Training Loss: 0.0185\n",
            "Validation Metrics:\n",
            "  loss: 0.3248\n",
            "  precision_micro: 0.8225\n",
            "  recall_micro: 0.6744\n",
            "  f1_micro: 0.7411\n",
            "  precision_macro: 0.4287\n",
            "  recall_macro: 0.4048\n",
            "  f1_macro: 0.4123\n",
            "  hamming_loss: 0.0057\n",
            "\n",
            "=== Epoch 12/15 ===\n",
            "Batch 0/762, Loss: 0.0027\n",
            "Batch 50/762, Loss: 0.0067\n",
            "Batch 100/762, Loss: 0.0144\n",
            "Batch 150/762, Loss: 0.0018\n",
            "Batch 200/762, Loss: 0.0059\n",
            "Batch 250/762, Loss: 0.0010\n",
            "Batch 300/762, Loss: 0.0109\n",
            "Batch 350/762, Loss: 0.0139\n",
            "Batch 400/762, Loss: 0.0270\n",
            "Batch 450/762, Loss: 0.0138\n",
            "Batch 500/762, Loss: 0.0187\n",
            "Batch 550/762, Loss: 0.0046\n",
            "Batch 600/762, Loss: 0.0044\n",
            "Batch 650/762, Loss: 0.0068\n",
            "Batch 700/762, Loss: 0.0276\n",
            "Batch 750/762, Loss: 0.0040\n",
            "Training Loss: 0.0155\n",
            "Validation Metrics:\n",
            "  loss: 0.3525\n",
            "  precision_micro: 0.8796\n",
            "  recall_micro: 0.6582\n",
            "  f1_micro: 0.7530\n",
            "  precision_macro: 0.4616\n",
            "  recall_macro: 0.3931\n",
            "  f1_macro: 0.4144\n",
            "  hamming_loss: 0.0052\n",
            "\n",
            "=== Epoch 13/15 ===\n",
            "Batch 0/762, Loss: 0.0039\n",
            "Batch 50/762, Loss: 0.0131\n",
            "Batch 100/762, Loss: 0.0136\n",
            "Batch 150/762, Loss: 0.0059\n",
            "Batch 200/762, Loss: 0.0054\n",
            "Batch 250/762, Loss: 0.0032\n",
            "Batch 300/762, Loss: 0.0044\n",
            "Batch 350/762, Loss: 0.0045\n",
            "Batch 400/762, Loss: 0.0023\n",
            "Batch 450/762, Loss: 0.0099\n",
            "Batch 500/762, Loss: 0.0136\n",
            "Batch 550/762, Loss: 0.0093\n",
            "Batch 600/762, Loss: 0.0021\n",
            "Batch 650/762, Loss: 0.0076\n",
            "Batch 700/762, Loss: 0.0054\n",
            "Batch 750/762, Loss: 0.0081\n",
            "Training Loss: 0.0134\n",
            "Validation Metrics:\n",
            "  loss: 0.3364\n",
            "  precision_micro: 0.8731\n",
            "  recall_micro: 0.6674\n",
            "  f1_micro: 0.7565\n",
            "  precision_macro: 0.4540\n",
            "  recall_macro: 0.4040\n",
            "  f1_macro: 0.4206\n",
            "  hamming_loss: 0.0052\n",
            "\n",
            "=== Epoch 14/15 ===\n",
            "Batch 0/762, Loss: 0.0402\n",
            "Batch 50/762, Loss: 0.0040\n",
            "Batch 100/762, Loss: 0.0432\n",
            "Batch 150/762, Loss: 0.0035\n",
            "Batch 200/762, Loss: 0.0644\n",
            "Batch 250/762, Loss: 0.0105\n",
            "Batch 300/762, Loss: 0.0088\n",
            "Batch 350/762, Loss: 0.0018\n",
            "Batch 400/762, Loss: 0.0023\n",
            "Batch 450/762, Loss: 0.0040\n",
            "Batch 500/762, Loss: 0.0030\n",
            "Batch 550/762, Loss: 0.0106\n",
            "Batch 600/762, Loss: 0.0014\n",
            "Batch 650/762, Loss: 0.0095\n",
            "Batch 700/762, Loss: 0.0062\n",
            "Batch 750/762, Loss: 0.0034\n",
            "Training Loss: 0.0123\n",
            "Validation Metrics:\n",
            "  loss: 0.3507\n",
            "  precision_micro: 0.8834\n",
            "  recall_micro: 0.6651\n",
            "  f1_micro: 0.7589\n",
            "  precision_macro: 0.4567\n",
            "  recall_macro: 0.3980\n",
            "  f1_macro: 0.4229\n",
            "  hamming_loss: 0.0051\n",
            "\n",
            "=== Epoch 15/15 ===\n",
            "Batch 0/762, Loss: 0.0095\n",
            "Batch 50/762, Loss: 0.0028\n",
            "Batch 100/762, Loss: 0.0469\n",
            "Batch 150/762, Loss: 0.0060\n",
            "Batch 200/762, Loss: 0.0312\n",
            "Batch 250/762, Loss: 0.0008\n",
            "Batch 300/762, Loss: 0.0045\n",
            "Batch 350/762, Loss: 0.0030\n",
            "Batch 400/762, Loss: 0.0037\n",
            "Batch 450/762, Loss: 0.0073\n",
            "Batch 500/762, Loss: 0.0052\n",
            "Batch 550/762, Loss: 0.0017\n",
            "Batch 600/762, Loss: 0.0236\n",
            "Batch 650/762, Loss: 0.0156\n",
            "Batch 700/762, Loss: 0.0042\n",
            "Batch 750/762, Loss: 0.0229\n",
            "Training Loss: 0.0116\n",
            "Validation Metrics:\n",
            "  loss: 0.3495\n",
            "  precision_micro: 0.8926\n",
            "  recall_micro: 0.6721\n",
            "  f1_micro: 0.7668\n",
            "  precision_macro: 0.4592\n",
            "  recall_macro: 0.4056\n",
            "  f1_macro: 0.4282\n",
            "  hamming_loss: 0.0050\n",
            "\n",
            "Training completed!\n"
          ]
        }
      ],
      "source": [
        "def train_epoch(model, train_loader, optimizer, scheduler, criterion):\n",
        "    \"\"\"Train for one epoch\"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch_idx, batch in enumerate(train_loader):\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(input_ids, attention_mask, labels)\n",
        "        loss = criterion(outputs['logits'], labels)\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), MAX_GRAD_NORM)\n",
        "\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        if batch_idx % 50 == 0:\n",
        "            print(f'Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item():.4f}')\n",
        "\n",
        "    return total_loss / len(train_loader)\n",
        "\n",
        "def evaluate(model, val_loader, criterion):\n",
        "    \"\"\"Evaluate the model\"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask, labels)\n",
        "            loss = criterion(outputs['logits'], labels)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Convert logits to predictions (threshold = 0.5)\n",
        "            predictions = torch.sigmoid(outputs['logits']) > 0.5\n",
        "\n",
        "            all_predictions.extend(predictions.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # Calculate metrics\n",
        "    all_predictions = np.array(all_predictions)\n",
        "    all_labels = np.array(all_labels)\n",
        "\n",
        "    # Micro and macro averages\n",
        "    from sklearn.metrics import precision_recall_fscore_support, hamming_loss\n",
        "\n",
        "    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(\n",
        "        all_labels, all_predictions, average='micro'\n",
        "    )\n",
        "\n",
        "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(\n",
        "        all_labels, all_predictions, average='macro'\n",
        "    )\n",
        "\n",
        "    hamming = hamming_loss(all_labels, all_predictions)\n",
        "\n",
        "    return {\n",
        "        'loss': total_loss / len(val_loader),\n",
        "        'precision_micro': precision_micro,\n",
        "        'recall_micro': recall_micro,\n",
        "        'f1_micro': f1_micro,\n",
        "        'precision_macro': precision_macro,\n",
        "        'recall_macro': recall_macro,\n",
        "        'f1_macro': f1_macro,\n",
        "        'hamming_loss': hamming\n",
        "    }\n",
        "\n",
        "# Training loop\n",
        "training_history = {'train_loss': [], 'val_metrics': []}\n",
        "\n",
        "print(\"Starting training...\")\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f\"\\n=== Epoch {epoch + 1}/{EPOCHS} ===\")\n",
        "\n",
        "    # Train\n",
        "    train_loss = train_epoch(model, train_loader, optimizer, scheduler, criterion)\n",
        "    print(f\"Training Loss: {train_loss:.4f}\")\n",
        "\n",
        "    # Evaluate\n",
        "    val_metrics = evaluate(model, val_loader, criterion)\n",
        "    print(f\"Validation Metrics:\")\n",
        "    for key, value in val_metrics.items():\n",
        "        print(f\"  {key}: {value:.4f}\")\n",
        "\n",
        "    # Save metrics\n",
        "    training_history['train_loss'].append(train_loss)\n",
        "    training_history['val_metrics'].append(val_metrics)\n",
        "\n",
        "    # Save checkpoint\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'train_loss': train_loss,\n",
        "        'val_metrics': val_metrics\n",
        "    }, f'../models/bert/checkpoint_epoch_{epoch+1}.pt')\n",
        "\n",
        "print(\"\\nTraining completed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gBC23NsDKX3"
      },
      "source": [
        "#### Evaluation and Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRTIyI_vDKX3",
        "outputId": "51d9de48-cdea-41b9-afc1-2485d757bfdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Test Results (Clean Clause Names) ===\n",
            "\n",
            "Overall Metrics:\n",
            "  loss: 0.1571\n",
            "  precision_micro: 0.8922\n",
            "  recall_micro: 0.7036\n",
            "  f1_micro: 0.7867\n",
            "  precision_macro: 0.5125\n",
            "  recall_macro: 0.5136\n",
            "  f1_macro: 0.4905\n",
            "  hamming_loss: 0.0041\n",
            "\n",
            "Top 10 Best Performing Clause Types (Clean Names):\n",
            "                   clean_clause_name  precision    recall        f1 support\n",
            "18                    Effective Date   1.000000  1.000000  1.000000    None\n",
            "26           Third Party Beneficiary   1.000000  1.000000  1.000000    None\n",
            "12                   Expiration Date   1.000000  0.976190  0.987952    None\n",
            "14  Irrevocable Or Perpetual License   0.961538  1.000000  0.980392    None\n",
            "3                   Cap On Liability   1.000000  0.869565  0.930233    None\n",
            "21            Revenue/Profit Sharing   1.000000  0.857143  0.923077    None\n",
            "24               Covenant Not To Sue   0.870968  0.964286  0.915254    None\n",
            "5            No-Solicit Of Employees   0.888889  0.941176  0.914286    None\n",
            "11                    Agreement Date   0.927778  0.893048  0.910082    None\n",
            "25                     License Grant   1.000000  0.833333  0.909091    None\n",
            "\n",
            "Bottom 10 Clause Types - Most Challenging (Clean Names):\n",
            "                     clean_clause_name  precision    recall        f1 support\n",
            "0                              Parties        0.0  0.000000  0.000000    None\n",
            "6                   Price Restrictions        0.0  0.000000  0.000000    None\n",
            "9   Notice Period To Terminate Renewal        0.0  0.000000  0.000000    None\n",
            "13                           Insurance        0.0  0.000000  0.000000    None\n",
            "19                   Change Of Control        0.0  0.000000  0.000000    None\n",
            "23                       Governing Law        0.0  0.000000  0.000000    None\n",
            "27                  Minimum Commitment        0.0  0.000000  0.000000    None\n",
            "2                      Anti-Assignment        1.0  0.007937  0.015748    None\n",
            "16                  Liquidated Damages        0.2  1.000000  0.333333    None\n",
            "17   Unlimited/All-You-Can-Eat-License        0.5  1.000000  0.666667    None\n",
            "\n",
            "Clause Frequency Distribution:\n",
            "  Governing Law: 657 samples\n",
            "  Anti-Assignment: 448 samples\n",
            "  Document Name: 178 samples\n",
            "  Insurance: 142 samples\n",
            "  Cap On Liability: 126 samples\n",
            "  Parties: 125 samples\n",
            "  Revenue/Profit Sharing: 91 samples\n",
            "  License Grant: 83 samples\n",
            "  Minimum Commitment: 81 samples\n",
            "  Third Party Beneficiary: 79 samples\n"
          ]
        }
      ],
      "source": [
        "def detailed_evaluation(model, test_loader, clean_clause_names):\n",
        "    \"\"\"Detailed evaluation with per-class metrics using clean clause names\"\"\"\n",
        "    model.eval()\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "    all_probs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask, labels)\n",
        "            probs = torch.sigmoid(outputs['logits'])\n",
        "            predictions = probs > 0.5\n",
        "\n",
        "            all_predictions.extend(predictions.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_probs.extend(probs.cpu().numpy())\n",
        "\n",
        "    all_predictions = np.array(all_predictions)\n",
        "    all_labels = np.array(all_labels)\n",
        "    all_probs = np.array(all_probs)\n",
        "\n",
        "    # Per-class metrics using clean clause names\n",
        "    per_class_metrics = []\n",
        "    for i, clean_clause_name in enumerate(clean_clause_names):\n",
        "        y_true = all_labels[:, i]\n",
        "        y_pred = all_predictions[:, i]\n",
        "        y_prob = all_probs[:, i]\n",
        "\n",
        "        if y_true.sum() > 0:  # Only calculate if positive samples exist\n",
        "            precision, recall, f1, support = precision_recall_fscore_support(\n",
        "                y_true, y_pred, average='binary'\n",
        "            )\n",
        "\n",
        "            per_class_metrics.append({\n",
        "                'clean_clause_name': clean_clause_name,\n",
        "                'precision': precision,\n",
        "                'recall': recall,\n",
        "                'f1': f1,\n",
        "                'support': support,\n",
        "                'predictions_made': y_pred.sum(),\n",
        "                'avg_probability': y_prob.mean()\n",
        "            })\n",
        "\n",
        "    return pd.DataFrame(per_class_metrics), all_predictions, all_labels, all_probs\n",
        "\n",
        "# Test the model with clean clause names\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "per_class_df, test_predictions, test_labels, test_probs = detailed_evaluation(\n",
        "    model, test_loader, clean_clause_names\n",
        ")\n",
        "\n",
        "print(\"=== Test Results (Clean Clause Names) ===\")\n",
        "print(\"\\nOverall Metrics:\")\n",
        "test_metrics = evaluate(model, test_loader, criterion)\n",
        "for key, value in test_metrics.items():\n",
        "    print(f\"  {key}: {value:.4f}\")\n",
        "\n",
        "print(f\"\\nTop 10 Best Performing Clause Types (Clean Names):\")\n",
        "best_clauses = per_class_df.nlargest(10, 'f1')[['clean_clause_name', 'precision', 'recall', 'f1', 'support']]\n",
        "print(best_clauses)\n",
        "\n",
        "print(f\"\\nBottom 10 Clause Types - Most Challenging (Clean Names):\")\n",
        "worst_clauses = per_class_df.nsmallest(10, 'f1')[['clean_clause_name', 'precision', 'recall', 'f1', 'support']]\n",
        "print(worst_clauses)\n",
        "\n",
        "# Show clause distribution\n",
        "print(f\"\\nClause Frequency Distribution:\")\n",
        "clause_freq = {}\n",
        "for labels in data['train']['labels']:\n",
        "    for label in labels:\n",
        "        clause_freq[label] = clause_freq.get(label, 0) + 1\n",
        "\n",
        "sorted_freq = sorted(clause_freq.items(), key=lambda x: x[1], reverse=True)[:10]\n",
        "for clause, freq in sorted_freq:\n",
        "    print(f\"  {clause}: {freq} samples\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIlbQhtZDKX3"
      },
      "source": [
        "#### Save Model and Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K77b49dsDKX3",
        "outputId": "3b43eb0f-d316-4d70-8c1e-8e8d85757249"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model and results saved with clean clause names!\n",
            "Model saved to: ../models/bert/\n",
            "Results saved to: ../models/bert/training_results.json\n",
            "Clean clause mapping saved to: ../models/bert/clean_clause_names.json\n",
            "\n",
            "Clean clause names integration completed!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.makedirs('../models/bert/', exist_ok=True)\n",
        "\n",
        "# Save the final model\n",
        "torch.save(model.state_dict(), '../models/bert/final_model.pt')\n",
        "\n",
        "# Save tokenizer\n",
        "tokenizer.save_pretrained('../models/bert/')\n",
        "\n",
        "# Save results with clean clause names\n",
        "results = {\n",
        "    'training_history': training_history,\n",
        "    'test_metrics': test_metrics,\n",
        "    'per_class_metrics': per_class_df.to_dict('records'),\n",
        "    'clean_clause_names': clean_clause_names,\n",
        "    'original_to_clean_mapping': original_to_clean,\n",
        "    'model_config': {\n",
        "        'model_name': MODEL_NAME,\n",
        "        'max_length': 512,\n",
        "        'batch_size': BATCH_SIZE,\n",
        "        'learning_rate': LEARNING_RATE,\n",
        "        'epochs': EPOCHS,\n",
        "        'num_labels': num_labels,\n",
        "        'uses_clean_clause_names': True\n",
        "    }\n",
        "}\n",
        "\n",
        "with open('../models/bert/training_results.json', 'w') as f:\n",
        "    json.dump(results, f, indent=2, default=str)\n",
        "\n",
        "# Save clean clause names mapping for future use\n",
        "with open('../models/bert/clean_clause_names.json', 'w') as f:\n",
        "    json.dump({\n",
        "        'clean_clause_names': clean_clause_names,\n",
        "        'original_to_clean_mapping': original_to_clean\n",
        "    }, f, indent=2)\n",
        "\n",
        "print(\"Model and results saved with clean clause names!\")\n",
        "print(f\"Model saved to: ../models/bert/\")\n",
        "print(f\"Results saved to: ../models/bert/training_results.json\")\n",
        "print(f\"Clean clause mapping saved to: ../models/bert/clean_clause_names.json\")\n",
        "print(f\"\\nClean clause names integration completed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BaoSZvy-DKX4",
        "outputId": "2b8a7ef4-16fe-4c6f-9f23-00e5467c8774"
      },
      "source": [
        "#### Key Benefits Summary of Legal NLP + Explainability Toolkit Training Notebook\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "print(\"KEY BENEFITS OF THIS TRAINING NOTEBOOK (WITH CLEAN CLAUSE NAMES)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "benefits = {\n",
        "    \"1. CLEAN CLAUSE NAME INTEGRATION\": [\n",
        "        \"Uses human-readable clause names (e.g., 'Agreement Date')\",\n",
        "        \"Eliminates verbose CUAD question format for clarity\",\n",
        "        \"Maintains mapping to original clause types for reference\",\n",
        "        f\"Training on {len(clean_clause_names)} clean clause types\"\n",
        "    ],\n",
        "\n",
        "    \"2. CLASS IMBALANCE HANDLING\": [\n",
        "        \"Weighted loss function based on clean clause frequencies\",\n",
        "        \"Addresses highly imbalanced legal clause distribution\",\n",
        "        \"Prevents model bias toward common clause types\",\n",
        "        f\"Custom class weights for clean clause names\"\n",
        "    ],\n",
        "\n",
        "    \"3. MULTI-LABEL CLASSIFICATION\": [\n",
        "        \"Handles documents with multiple simultaneous clause types\",\n",
        "        \"BCEWithLogitsLoss for independent label predictions\",\n",
        "        \"Sigmoid activation for probability-based thresholding\",\n",
        "        \"Real-world legal document complexity support\"\n",
        "    ],\n",
        "\n",
        "    \"4. COMPREHENSIVE EVALUATION\": [\n",
        "        \"Per-class metrics using clean clause names\",\n",
        "        \"Micro/macro precision, recall, F1 metrics\",\n",
        "        \"Hamming loss for multi-label performance\",\n",
        "        \"Interpretable results for legal practitioners\"\n",
        "    ],\n",
        "\n",
        "    \"5. ROBUST TRAINING INFRASTRUCTURE\": [\n",
        "        \"Model checkpointing for recovery and analysis\",\n",
        "        \"Learning rate scheduling with warmup\",\n",
        "        \"Gradient clipping for training stability\",\n",
        "        \"Progress tracking with clean name reporting\"\n",
        "    ],\n",
        "\n",
        "    \"6. PRODUCTION-READY OUTPUTS\": [\n",
        "        \"Trained model weights and tokenizer saved\",\n",
        "        \"Clean clause name mappings preserved\",\n",
        "        \"Comprehensive training results with readable names\",\n",
        "        \"Foundation for explainability analysis\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "for category, items in benefits.items():\n",
        "    print(f\"\\n{category}\")\n",
        "    print(\"-\" * 50)\n",
        "    for item in items:\n",
        "        print(f\"  {item}\")\n",
        "\n",
        "print(f\"\\n TRAINING SETUP SUMMARY (CLEAN NAMES)\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"  Model: {MODEL_NAME}\")\n",
        "print(f\"  Training samples: {len(train_dataset):,}\")\n",
        "print(f\"  Validation samples: {len(val_dataset):,}\")\n",
        "print(f\"  Test samples: {len(test_dataset):,}\")\n",
        "print(f\"  Clean clause types: {num_labels}\")\n",
        "print(f\"  Training epochs: {EPOCHS}\")\n",
        "print(f\"  Learning rate: {LEARNING_RATE}\")\n",
        "\n",
        "print(f\"\\n CLEAN CLAUSE NAME EXAMPLES\")\n",
        "print(\"-\" * 50)\n",
        "sample_names = clean_clause_names[:8]\n",
        "for name in sample_names:\n",
        "    print(f\"   {name}\")\n",
        "if len(clean_clause_names) > 8:\n",
        "    print(f\"  ... and {len(clean_clause_names) - 8} more clause types\")\n",
        "\n",
        "print(f\"\\n WHAT THIS ENABLES\")\n",
        "print(\"-\" * 50)\n",
        "print(\"Multi-label BERT model with readable clause names\")\n",
        "print(\"Legal practitioner-friendly model outputs\")\n",
        "print(\"Proper handling of class imbalance from EDA findings\")\n",
        "print(\"Comprehensive evaluation metrics for legal domain\")\n",
        "print(\"Foundation for explainability analysis (LIME, SHAP)\")\n",
        "print(\"Production-ready legal document processing pipeline\")\n",
        "\n",
        "print(f\"\\n NEXT STEPS\")\n",
        "print(\"-\" * 50)\n",
        "print(\"   Run training loop to train the model\")\n",
        "print(\"   Analyze per-class performance with clean names\")\n",
        "print(\"   Implement explainability techniques\")\n",
        "print(\"   Deploy for legal document clause extraction\")\n",
        "print(\"   Generate human-readable model explanations\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "legal_nlp_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
